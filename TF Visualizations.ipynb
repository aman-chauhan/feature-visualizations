{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Colaboratory Notebook.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dcN7Lki_vSOd","colab_type":"text"},"source":["# Feature Visualizations"]},{"cell_type":"markdown","metadata":{"id":"J2cv0hEFvYhx","colab_type":"text"},"source":["## Required Packages"]},{"cell_type":"code","metadata":{"id":"iQkjBZL8xRg3","colab_type":"code","outputId":"d4919c62-52b4-462f-8ec8-ca73c22fa509","executionInfo":{"status":"ok","timestamp":1562870606026,"user_tz":420,"elapsed":3138,"user":{"displayName":"Aman Chauhan","photoUrl":"https://lh5.googleusercontent.com/--qB8FM5XjUU/AAAAAAAAAAI/AAAAAAAADUk/B3gi4Udqj0s/s64/photo.jpg","userId":"17170189210337171161"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","from progressbar import ProgressBar, Bar, Percentage\n","from skimage.restoration import denoise_bilateral\n","from keras.optimizers import Adadelta, Adam\n","from skimage.transform import resize\n","from skimage.filters import gaussian\n","from imageio import imwrite, imread\n","from keras.layers import Lambda\n","from keras.layers import Input\n","from keras import regularizers\n","from keras import backend as K\n","from keras import Model\n","\n","import tensorflow as tf\n","import numpy as np\n","import sys\n","import os"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"NzLe5YCz5FD-","colab_type":"text"},"source":["## Init"]},{"cell_type":"code","metadata":{"id":"fOa_jUHF5N1z","colab_type":"code","colab":{}},"source":["def make_directories():\n","    if not os.path.exists('docs'):\n","        os.mkdir('docs')\n","\n","    if not os.path.exists('bin'):\n","        os.mkdir('bin')\n","\n","    if not os.path.exists(os.path.join('bin', 'shapes')):\n","        os.mkdir(os.path.join('bin', 'shapes'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgSN6rvx5dUs","colab_type":"code","colab":{}},"source":["make_directories()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t3brD4S_5rFx","colab_type":"text"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"ws_hcwCOVgeH","colab_type":"code","colab":{}},"source":["# referenced from https://github.com/tensorflow/lucid/blob/master/lucid/optvis/overrides/redirected_relu_grad.py#L90\n","\n","@tf.RegisterGradient('RedirectedRelu')\n","def redirected_relu_grad(op, grad):\n","    x = op.inputs[0]\n","    relu_grad = tf.where(x < 0., tf.zeros_like(grad), grad)\n","    neg_pushing_lower = tf.logical_and(x < 0., grad > 0.)\n","    redirected_grad = tf.where(neg_pushing_lower, tf.zeros_like(grad), grad)\n","    assert_op = tf.Assert(tf.greater(tf.rank(relu_grad), 1), [tf.rank(relu_grad)])\n","    with tf.control_dependencies([assert_op]):\n","        batch = tf.shape(relu_grad)[0]\n","        reshaped_relu_grad = tf.reshape(relu_grad, [batch, -1])\n","        relu_grad_mag = tf.norm(reshaped_relu_grad, axis=1)\n","    result_grad = tf.where(relu_grad_mag > 0., relu_grad, redirected_grad)\n","    return result_grad"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGUw8CddVnrn","colab_type":"code","colab":{}},"source":["# referenced from https://github.com/tensorflow/lucid/blob/master/lucid/optvis/overrides/redirected_relu_grad.py#L117\n","\n","@tf.RegisterGradient('RedirectedRelu6')\n","def redirected_relu6_grad(op, grad):\n","    x = op.inputs[0]\n","    relu6_cond = tf.logical_or(x < 0., x > 6.)\n","    relu_grad = tf.where(relu6_cond, tf.zeros_like(grad), grad)\n","    neg_pushing_lower = tf.logical_and(x < 0., grad > 0.)\n","    pos_pushing_higher = tf.logical_and(x > 6., grad < 0.)\n","    dir_filter = tf.logical_or(neg_pushing_lower, pos_pushing_higher)\n","    redirected_grad = tf.where(dir_filter, tf.zeros_like(grad), grad)\n","    assert_op = tf.Assert(tf.greater(tf.rank(relu_grad), 1), [tf.rank(relu_grad)])\n","    with tf.control_dependencies([assert_op]):\n","        batch = tf.shape(relu_grad)[0]\n","        reshaped_relu_grad = tf.reshape(relu_grad, [batch, -1])\n","        relu_grad_mag = tf.norm(reshaped_relu_grad, axis=1)\n","    result_grad = tf.where(relu_grad_mag > 0., relu_grad, redirected_grad)\n","    return result_grad"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpbbC6jd5ejA","colab_type":"code","colab":{}},"source":["def get_model(model_name):\n","    model = None\n","    if model_name == 'mobile-net-v1':\n","        from keras.applications.mobilenet import MobileNet\n","        model = MobileNet(weights='imagenet', include_top=False,\n","                          input_shape=(None, None, 3))\n","    elif model_name == 'mobile-net-v2':\n","        from keras.applications.mobilenet_v2 import MobileNetV2\n","        model = MobileNetV2(weights='imagenet', include_top=False,\n","                            input_shape=(None, None, 3))\n","    elif model_name == 'vgg-16':\n","        from keras.applications.vgg16 import VGG16\n","        model = VGG16(weights='imagenet', include_top=False,\n","                      input_shape=(None, None, 3))\n","    elif model_name == 'vgg-19':\n","        from keras.applications.vgg19 import VGG19\n","        model = VGG19(weights='imagenet', include_top=False,\n","                      input_shape=(None, None, 3))\n","    elif model_name == 'densenet-121':\n","        from keras.applications.densenet import DenseNet121\n","        model = DenseNet121(weights='imagenet', include_top=False,\n","                            input_shape=(None, None, 3))\n","    elif model_name == 'densenet-169':\n","        from keras.applications.densenet import DenseNet169\n","        model = DenseNet169(weights='imagenet', include_top=False,\n","                            input_shape=(None, None, 3))\n","    elif model_name == 'densenet-201':\n","        from keras.applications.densenet import DenseNet201\n","        model = DenseNet201(weights='imagenet', include_top=False,\n","                            input_shape=(None, None, 3))\n","    elif model_name == 'resnet-50':\n","        from keras.applications.resnet50 import ResNet50\n","        model = ResNet50(weights='imagenet', include_top=False,\n","                         input_shape=(None, None, 3))\n","    elif model_name == 'xception':\n","        from keras.applications.xception import Xception\n","        model = Xception(weights='imagenet', include_top=False,\n","                         input_shape=(None, None, 3))\n","    elif model_name == 'inception-v3':\n","        from keras.applications.inception_v3 import InceptionV3\n","        model = InceptionV3(weights='imagenet', include_top=False,\n","                            input_shape=(None, None, 3))\n","    elif model_name == 'inceptionresnet-v2':\n","        from keras.applications.inception_resnet_v2 import InceptionResNetV2\n","        model = InceptionResNetV2(weights='imagenet', include_top=False,\n","                                  input_shape=(None, None, 3))\n","    # for layer in model.layers:\n","    #     layer.trainable = False\n","    # model.compile('adadelta', 'mse')\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvCGlB995zv1","colab_type":"code","colab":{}},"source":["def deprocess_image(x):\n","    return np.clip(((x - np.min(x)) / (np.max(x) - np.min(x))) * 255.0, 0, 255).astype('uint8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffSGfudY525p","colab_type":"code","colab":{}},"source":["def gaussian_blur(x, r):\n","    return gaussian(x, sigma=[0, r, r, 0], multichannel=True, preserve_range=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFJNpsBf5476","colab_type":"code","colab":{}},"source":["def denoise(x, color, spatial):\n","    x = denoise_bilateral(x, sigma_color=color, sigma_spatial=spatial,\n","                          mode='reflect', multichannel=True)\n","    return np.clip(x, 0, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NBBD68qM57RZ","colab_type":"code","colab":{}},"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsCATcMV593_","colab_type":"code","colab":{}},"source":["def logit(x):\n","    return np.log(x / (1 - x))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YuK6wwKF6qLt","colab_type":"text"},"source":["## Sample Generator"]},{"cell_type":"code","metadata":{"id":"R4TAl-Ho6vch","colab_type":"code","colab":{}},"source":["def main(model_name, layer_name, img_size):\n","    if not os.path.exists(os.path.join('bin', model_name)):\n","        os.mkdir(os.path.join('bin', model_name))\n","    if not os.path.exists(os.path.join('bin', os.path.join(model_name, layer_name.split('/')[0]))):\n","        os.mkdir(os.path.join('bin', os.path.join(model_name, layer_name.split('/')[0])))\n","        \n","    np.random.seed(10)\n","\n","    base_model = None\n","    layer_dict = None\n","    model = None\n","    \n","    with K.get_session().graph.gradient_override_map({'Relu': 'RedirectedRelu', 'Relu6': 'RedirectedRelu6'}):\n","        base_model = get_model(model_name)\n","        layer_dict = dict([(layer.name, layer) for layer in base_model.layers])\n","        print(layer_dict)\n","        model = Model(inputs=layer_dict['input_1'].input, outputs=layer_dict[layer_name].output)\n","        datagen = ImageDataGenerator(rotation_range=30, fill_mode='reflect',\n","                                     zoom_range=0.1)\n","        regularization = regularizers.l2(0.001)\n","        optimization = Adam(lr=0.05)\n","        \n","        bar = ProgressBar(maxval=layer_dict[layer_name].output_shape[3],\n","                          widgets=[Bar('=', '[', ']'), ' ', Percentage()]).start()\n","\n","        for i in range(layer_dict[layer_name].output_shape[3]):\n","            img_placeholder = K.placeholder(name='img_placeholder',\n","                                            shape=(2, img_size, img_size, 3))\n","            img_parameters = K.zeros(shape=(2, img_size, img_size, 3))\n","            img_parameters = K.update(img_parameters, img_placeholder)\n","            model_output = model(img_parameters)\n","            loss = K.mean(model_output[0, :, :, i]) - K.mean(model_output[1, :, :, i])\n","#             loss += regularization(img_parameters)\n","#             loss += 0.00001 * tf.reduce_sum(tf.image.total_variation(img_parameters))\n","            updates = optimization.get_updates(loss, [img_parameters])\n","            iterate = K.function(inputs=[img_placeholder, K.learning_phase()],\n","                                 outputs=[img_parameters, loss], updates=updates)\n","\n","            radius = 0.25\n","            img = np.random.normal(size=(2, img_size, img_size, 3), loc=128.0, scale=0.01)\n","            filepath = os.path.join('bin', os.path.join(model_name,\n","                                                        layer_name.split('/')[0]))\n","            pos_name = os.path.join(filepath, 'pos-{:04d}.png'.format(i))\n","            neg_name = os.path.join(filepath, 'neg-{:04d}.png'.format(i))\n","            if os.path.exists(pos_name):\n","                pos_img = imread(pos_name)\n","                pos_img = (pos_img - pos_img.min()) / (pos_img.max() - pos_img.min())\n","                neg_img = imread(neg_name)\n","                neg_img = (neg_img - neg_img.min()) / (neg_img.max() - neg_img.min())\n","\n","                if pos_img.shape[0] < img[0].shape[0]:\n","                    img[0] = resize(pos_img, img[0].shape[:2], preserve_range=True)\n","                    img[1] = resize(neg_img, img[1].shape[:2], preserve_range=True)\n","                    img = gaussian_blur(img, radius)\n","                else:\n","                    img[0] = pos_img\n","                    img[1] = neg_img\n","\n","            best_pos = None\n","            best_neg = None\n","            minloss = float('inf')\n","            chance = 0\n","            cnt = 0\n","            while True:\n","                cnt += 1\n","                img, loss = iterate([img, 0])\n","\n","                img = gaussian_blur(img, radius)\n","\n","                if loss <= minloss:\n","                    minloss = loss\n","                    chance = 0\n","                    best_pos = img[0]\n","                    best_neg = img[1]\n","                else:\n","                    chance += 1\n","\n","                if cnt % 512 == 0:\n","                    imwrite(pos_name, deprocess_image(best_pos))\n","                    imwrite(neg_name, deprocess_image(best_neg))\n","\n","                if chance == 128:\n","                    break\n","            imwrite(pos_name, deprocess_image(best_pos))\n","            imwrite(neg_name, deprocess_image(best_neg))\n","            bar.update(i + 1)\n","    bar.finish()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0r32ENdBLZH","colab_type":"code","outputId":"614a308f-dffd-46a6-f62e-86944f740afe","executionInfo":{"status":"error","timestamp":1562870685071,"user_tz":420,"elapsed":82042,"user":{"displayName":"Aman Chauhan","photoUrl":"https://lh5.googleusercontent.com/--qB8FM5XjUU/AAAAAAAAAAI/AAAAAAAADUk/B3gi4Udqj0s/s64/photo.jpg","userId":"17170189210337171161"}},"colab":{"base_uri":"https://localhost:8080/","height":682}},"source":["main('mobile-net-v1', 'conv1', 128)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0711 18:43:26.093011 140390420174720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0711 18:43:26.094771 140390420174720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0711 18:43:26.096078 140390420174720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0711 18:43:26.209385 140390420174720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  warnings.warn('`input_shape` is undefined or non-square, '\n","W0711 18:43:26.211840 140390420174720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0711 18:43:26.550059 140390420174720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n","17227776/17225924 [==============================] - 1s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["\r                                                                               \r\r[                                                                        ] N/A%"],"name":"stderr"},{"output_type":"stream","text":["{'input_1': <keras.engine.input_layer.InputLayer object at 0x7faef8f13860>, 'conv1_pad': <keras.layers.convolutional.ZeroPadding2D object at 0x7faeee4c0fd0>, 'conv1': <keras.layers.convolutional.Conv2D object at 0x7faeee4c0908>, 'conv1_bn': <keras.layers.normalization.BatchNormalization object at 0x7faf0f3d24a8>, 'conv1_relu': <keras.layers.advanced_activations.ReLU object at 0x7faf0f431be0>, 'conv_dw_1': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faeee4db1d0>, 'conv_dw_1_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee8cc3828>, 'conv_dw_1_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8c92fd0>, 'conv_pw_1': <keras.layers.convolutional.Conv2D object at 0x7faee8c42f98>, 'conv_pw_1_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee8bc0160>, 'conv_pw_1_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8bc0f60>, 'conv_pad_2': <keras.layers.convolutional.ZeroPadding2D object at 0x7faee8b3fa20>, 'conv_dw_2': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee8b3fd30>, 'conv_dw_2_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee8a33860>, 'conv_dw_2_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8a33ef0>, 'conv_pw_2': <keras.layers.convolutional.Conv2D object at 0x7faee89a3748>, 'conv_pw_2_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee8a01e48>, 'conv_pw_2_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee89c3828>, 'conv_dw_3': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee89176d8>, 'conv_dw_3_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee895dba8>, 'conv_dw_3_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8885e80>, 'conv_pw_3': <keras.layers.convolutional.Conv2D object at 0x7faee884fef0>, 'conv_pw_3_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee87e4f60>, 'conv_pw_3_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee877ab38>, 'conv_pad_4': <keras.layers.convolutional.ZeroPadding2D object at 0x7faee8744e80>, 'conv_dw_4': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee8757fd0>, 'conv_dw_4_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee8668be0>, 'conv_dw_4_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee86686a0>, 'conv_pw_4': <keras.layers.convolutional.Conv2D object at 0x7faee8693eb8>, 'conv_pw_4_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee8642128>, 'conv_pw_4_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8601f28>, 'conv_dw_5': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee857ef98>, 'conv_dw_5_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee85367b8>, 'conv_dw_5_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee84f3fd0>, 'conv_pw_5': <keras.layers.convolutional.Conv2D object at 0x7faee84613c8>, 'conv_pw_5_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee8423a58>, 'conv_pw_5_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8402278>, 'conv_pad_6': <keras.layers.convolutional.ZeroPadding2D object at 0x7faee8352438>, 'conv_dw_6': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee83948d0>, 'conv_dw_6_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee82b5c88>, 'conv_dw_6_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee82b57f0>, 'conv_pw_6': <keras.layers.convolutional.Conv2D object at 0x7faee822deb8>, 'conv_pw_6_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee828eba8>, 'conv_pw_6_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee821fd68>, 'conv_dw_7': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee81a1f28>, 'conv_dw_7_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee817e518>, 'conv_dw_7_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8110fd0>, 'conv_pw_7': <keras.layers.convolutional.Conv2D object at 0x7faee80bef60>, 'conv_pw_7_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee80741d0>, 'conv_pw_7_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee8031eb8>, 'conv_dw_8': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee7fada20>, 'conv_dw_8_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7fe1d68>, 'conv_dw_8_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7f9e1d0>, 'conv_pw_8': <keras.layers.convolutional.Conv2D object at 0x7faee7e8b518>, 'conv_pw_8_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7ed1780>, 'conv_pw_8_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7e2c4e0>, 'conv_dw_9': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee7d7f588>, 'conv_dw_9_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7dc7a20>, 'conv_dw_9_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7cf1dd8>, 'conv_pw_9': <keras.layers.convolutional.Conv2D object at 0x7faee7cb8e48>, 'conv_pw_9_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7ccffd0>, 'conv_pw_9_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7c61b70>, 'conv_dw_10': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee7baceb8>, 'conv_dw_10_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7bc0588>, 'conv_dw_10_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7b53dd8>, 'conv_pw_10': <keras.layers.convolutional.Conv2D object at 0x7faee7acce48>, 'conv_pw_10_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7ab16d8>, 'conv_pw_10_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7a72dd8>, 'conv_dw_11': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee79c2f60>, 'conv_dw_11_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee79a77b8>, 'conv_dw_11_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7965f98>, 'conv_pw_11': <keras.layers.convolutional.Conv2D object at 0x7faee78d5320>, 'conv_pw_11_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee791cb38>, 'conv_pw_11_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee78731d0>, 'conv_pad_12': <keras.layers.convolutional.ZeroPadding2D object at 0x7faee77c4390>, 'conv_dw_12': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee78074e0>, 'conv_dw_12_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7742668>, 'conv_dw_12_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7742748>, 'conv_pw_12': <keras.layers.convolutional.Conv2D object at 0x7faee76fbf98>, 'conv_pw_12_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee7710f60>, 'conv_pw_12_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7626cc0>, 'conv_dw_13': <keras.layers.convolutional.DepthwiseConv2D object at 0x7faee75a4e80>, 'conv_dw_13_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee76046d8>, 'conv_dw_13_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee7575ba8>, 'conv_pw_13': <keras.layers.convolutional.Conv2D object at 0x7faee74b0630>, 'conv_pw_13_bn': <keras.layers.normalization.BatchNormalization object at 0x7faee750fda0>, 'conv_pw_13_relu': <keras.layers.advanced_activations.ReLU object at 0x7faee749ee48>}\n"],"name":"stdout"},{"output_type":"stream","text":["\r                                                                               \r\r[==                                                                      ]   3%"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-fb10b61f88dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mobile-net-v1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-bb4a8a1b5f3d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model_name, layer_name, img_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_blur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"WMBtZa8t4KdJ","colab_type":"code","colab":{}},"source":["#!zip -r inception-v3-2 bin/inception-v3/conv2d_2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KuszmTZJHNOc","colab_type":"code","colab":{}},"source":["#!rm -rf bin"],"execution_count":0,"outputs":[]}]}